############## IMPORT LIBRARIES ########################

import nltk
from nltk.corpus import stopwords
from textblob import TextBlob
from spellchecker import SpellChecker
from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPTNeoForCausalLM
from sklearn.metrics.pairwise import cosine_similarity
import torch
import numpy as np
import requests
from bs4 import BeautifulSoup
import warnings
import re
warnings.filterwarnings("ignore")
nltk.download('punkt')
nltk.download('stopwords')




#################### FUNCTION : Get Article Content from URL ##################

def get_article():
    print("__________________________________")
    url = input("Enter Blog URL : ")
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        para_tags = soup.find_all('p')
        all_para = [para.get_text() for para in para_tags]
        article_text = "".join(all_para)
        article_text = re.sub(r'<.*?>|\n|\t', '', article_text)
        return article_text
    else:
        print('----Something went wrong----')
        return False



#################### FUNCTION : Get Keywords from user ##################

def get_keywords():
    # Take input for relevant_keywords as a comma-separated string and convert it to a list
    relevant_keywords_input = input("Enter relevant keywords (comma-separated): ")
    relevant_keywords = [keyword.strip() for keyword in relevant_keywords_input.split(",")]
    return relevant_keywords



#################### FUNCTION : Check that article is generated by AI ##################

def is_generated_by_language_model(article):
    # Load GPT-2 tokenizer and model
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    model = GPT2LMHeadModel.from_pretrained("gpt2")

    # Load GPT-3.5 tokenizer and model
    tokenizer = GPT2Tokenizer.from_pretrained("EleutherAI/gpt-neo-1.3B")
    model = GPTNeoForCausalLM.from_pretrained("EleutherAI/gpt-neo-1.3B")

    # Tokenize the original article
    inputs = tokenizer.encode(article, return_tensors="pt", add_special_tokens=True)

    # Generate text using the GPT-2 model
    with torch.no_grad():
        outputs = model.generate(inputs, max_length=100, num_return_sequences=1)

    # Decode the generated tokens
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Truncate or pad the generated text to match the length of the original article
    max_length = max(len(inputs[0]), len(outputs[0]))
    inputs = torch.nn.functional.pad(inputs, (0, max_length - len(inputs[0])))
    outputs = torch.nn.functional.pad(outputs, (0, max_length - len(outputs[0])))

    # Calculate cosine similarity between original article and generated text
    embeddings = model.get_input_embeddings()(inputs).squeeze().detach().numpy()
    generated_embeddings = model.get_input_embeddings()(outputs).squeeze().detach().numpy()

    # Reshape embeddings to 2D arrays
    embeddings = embeddings.reshape(1, -1)
    generated_embeddings = generated_embeddings.reshape(1, -1)

    similarity = cosine_similarity(embeddings, generated_embeddings)[0, 0]

    # Map similarity score to effort score on a scale of 0 to 1
    effort_score = (similarity + 1) / 2  # Mapping from [-1, 1] to [0, 1]

    if effort_score > 70:
      return 1
    else:
      return 0




################ FUNCTION : Evaluate the Quality of the Article ##################

def evaluate_article_quality(article, is_written_by_chatgpt):
    # Readability score
    readability_score = TextBlob(article).sentiment.polarity

    # Vocabulary richness (Simple measure: Count unique words)
    words = TextBlob(article).words
    unique_words_count = len(set(words))
    total_words_count = len(words)
    vocabulary_score = unique_words_count / total_words_count

    # Spelling check using pyspellchecker
    spell = SpellChecker()
    misspelled_words = spell.unknown(words)
    spelling_error_count = len(misspelled_words)
    spelling_error_score = 1.0 - (spelling_error_count / total_words_count)


    # relevant_keywords = ["study plan", "IBPS Clerk", "academic success", "exam", "2023"]

    relevant_keywords = get_keywords()
    relevance_score = sum(keyword.lower() in article.lower() for keyword in relevant_keywords) / len(relevant_keywords)

    # Effort check for content written by ChatGPT
    effort_score = 1.0 if not is_written_by_chatgpt else 0.0

    # Calculate the quality score (You can customize the weights as needed)
    quality_score = (
        0.4 * readability_score + 0.1 * vocabulary_score + 0.3 * relevance_score - 0.1 * effort_score - 0.1 * spelling_error_score 
    )

    # Scale the quality score to percentage (0 to 100)
    score_percentage = (quality_score + 1) * 50  # Mapping from [-1, 1] to [0, 100]

    # Calculate the contribution of each score to the overall score
    contributions = {
        "Readability": (0.5 * readability_score / quality_score) * 100,
        "Vocabulary Richness": (0.1 * vocabulary_score / quality_score) * 100,
        "Relevance": (0.2 * relevance_score / quality_score) * 100,
        "Generated by AI": (0.1 * effort_score / quality_score) * 100,
        "Spelling Error": (0.1 * spelling_error_score / quality_score) * 100,
    }

    return score_percentage, contributions




################ Call Functions ##############

article_text = get_article()
is_written_by_chatgpt = is_generated_by_language_model(article_text)
print(is_written_by_chatgpt)
score_percentage, contributions = evaluate_article_quality(article_text, is_written_by_chatgpt)
print("__________________________________")
print("Score Percentage:", score_percentage)
print("__________________________________")
print("Contributions:")
for score, contribution in contributions.items():
    print("-----------------")
    print(f"{score}: {contribution:.2f}%")